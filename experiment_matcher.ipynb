{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding simulation parameters that best match experimental spiking profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif', serif='cm')\n",
    "\n",
    "plt.rcParams['figure.titlesize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 8\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "plt.rcParams['axes.labelpad'] = 3.0\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "# comment out the next line if not working on a retina-display computer\n",
    "import IPython\n",
    "IPython.display.set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.optimize as optimize\n",
    "import scipy.stats as stats\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import cPickle as pickle\n",
    "\n",
    "import emcee\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simulation\n",
    "from basic_defs import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lognormal_to_meanstdev(mu, sigma):\n",
    "    \"\"\" Find lognormal mean and standard deviation given mu and sigma\n",
    "    parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "      mu, sigma\n",
    "          Mean and standard deviation of associated normal distribution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      (mean, stdev)\n",
    "          Mean and standard deviation of lognormal distribution.\n",
    "    \"\"\"\n",
    "    return (np.exp(mu + sigma**2/2), \n",
    "            np.sqrt((np.exp(sigma**2) - 1)*np.exp(2*mu + sigma**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bursts(isi, percentile_threshold_in=65, percentile_threshold_out=80, min_spikes=3,\n",
    "                isi_in=1.0/80.0, isi_out=1.0/40.0, return_idxs=False):\n",
    "    \"\"\" Find the bursts in a vector ISIs.\n",
    "    \n",
    "    Bursts are returned as a vector of tuples, (start, end), giving times of burst start\n",
    "    and end using the first spike in the recording as a reference point.\n",
    "    \n",
    "    Change `percentile_threshold_in` and `percentile_threshold_out` to set the threshold for\n",
    "    entering a burst and exiting one, respectively. Low percentile means low ISI threshold.\n",
    "    The values are in percent.\n",
    "    \n",
    "    If `isi_in` and `isi_out` are not `None`, they are used instead.\n",
    "    \n",
    "    A burst will only be recorded if it has at least `min_spikes` spikes.\n",
    "    \n",
    "    If `return_idxs` is `True`, the function also returns the pairs of indices where bursts\n",
    "    start and end.\n",
    "    \"\"\"\n",
    "    isi = np.asarray(isi)\n",
    "    \n",
    "    if isi_in is None:\n",
    "        isi_threshold_in = np.percentile(isi, percentile_threshold_in)\n",
    "    else:\n",
    "        isi_threshold_in = isi_in\n",
    "    \n",
    "    if isi_out is None:\n",
    "        isi_threshold_out = np.percentile(isi, percentile_threshold_out)\n",
    "    else:\n",
    "        isi_threshold_out = isi_out\n",
    "    \n",
    "    # places where bursts may start\n",
    "    starts = (isi < isi_threshold_in).nonzero()[0]\n",
    "    # ...and end\n",
    "    ends = (isi >= isi_threshold_out).nonzero()[0]\n",
    "    \n",
    "    # find the first burst that starts, then find the first ending after that,\n",
    "    # then move to the next starting point, etc.\n",
    "    if len(starts) > 0:\n",
    "        crt_start = starts[0]\n",
    "        res0 = []\n",
    "        res = []\n",
    "        \n",
    "        # res0 contains start and end *indices*\n",
    "        # transform them to times\n",
    "        times = np.hstack(([0], np.cumsum(isi)))\n",
    "        \n",
    "        while True:\n",
    "            idx = (ends > crt_start).nonzero()[0]\n",
    "            if len(idx) == 0:\n",
    "                # we're done, burst ends at end of simulation\n",
    "                res0.append((crt_start, len(isi)))\n",
    "                break\n",
    "\n",
    "            crt_end = ends[idx[0]]\n",
    "            \n",
    "            if crt_end - crt_start + 1 >= min_spikes:\n",
    "                res0.append((crt_start, crt_end))\n",
    "                res.append((times[crt_start], times[crt_end]))\n",
    "            idx = (starts > crt_end).nonzero()[0]\n",
    "            if len(idx) == 0:\n",
    "                # no more bursts\n",
    "                break\n",
    "            \n",
    "            crt_start = starts[idx[0]]\n",
    "    else:\n",
    "        # no bursts\n",
    "        res = []\n",
    "        res0 = []\n",
    "    \n",
    "    if not return_idxs:\n",
    "        return res\n",
    "    else:\n",
    "        return (res, res0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(isi, max_trustworthy=1.0):\n",
    "    \"\"\" Calculate several summary statistics about the spikes that generated the given vector\n",
    "    of inter-spike intervals (ISIs).\n",
    "    \n",
    "    The `isi` vector is in assumed to be in seconds. ISIs that go above `max_trustworthy` are\n",
    "    ignored -- these are assumed to be inter-trial intervals.\n",
    "    \"\"\"\n",
    "    isi = isi[isi <= max_trustworthy]\n",
    "    \n",
    "    t_max = float(np.sum(isi))\n",
    "    n_spikes = 1 + len(isi)\n",
    "    \n",
    "    if t_max > 0:\n",
    "        firing_rate = n_spikes/t_max\n",
    "    else:\n",
    "        firing_rate = 0.0\n",
    "    \n",
    "    if len(isi) > 0:\n",
    "        isi_mean = np.mean(isi)\n",
    "        isi_std = np.std(isi)\n",
    "        isi_skew = stats.skew(isi, bias=False)\n",
    "        if isi_mean > 0:\n",
    "            fano_factor = np.var(isi) / isi_mean\n",
    "            cv = isi_std / isi_mean\n",
    "        else:\n",
    "            fano_factor = 0.0\n",
    "            cv = 0.0\n",
    "    else:\n",
    "        isi_mean = 0.0\n",
    "        isi_std = 0.0\n",
    "        fano_factor = 0.0\n",
    "        cv = 0.0\n",
    "    \n",
    "    bursts, bursts_idxs = find_bursts(isi, return_idxs=True)\n",
    "    if t_max > 0:\n",
    "        burst_rate = len(bursts)/t_max\n",
    "    else:\n",
    "        burst_rate = 0.0\n",
    "        \n",
    "    burst_lengths = np.asarray([_[1] - _[0] for _ in bursts])\n",
    "    \n",
    "    if len(burst_lengths) > 0:\n",
    "        burst_mean_length = np.mean(burst_lengths)\n",
    "    else:\n",
    "        burst_mean_length = 0.0\n",
    "    \n",
    "    # number of spikes for each burst\n",
    "    burst_nspikes = np.asarray([_[1] - _[0] + 1 for _ in bursts_idxs])\n",
    "    burst_total_time = np.sum(burst_lengths)\n",
    "    if burst_total_time > 0:\n",
    "        firing_rate_bursts = np.sum(burst_nspikes)/burst_total_time\n",
    "    else:\n",
    "        firing_rate_bursts = 0.0\n",
    "\n",
    "    return {\n",
    "        'firing_rate': firing_rate,\n",
    "        'isi_mean': isi_mean,\n",
    "        'isi_std': isi_std,\n",
    "        'isi_skew': isi_skew,\n",
    "        'fano_factor': fano_factor,\n",
    "        'cv': cv,\n",
    "        'burst_rate': burst_rate,\n",
    "        'burst_mean_length': burst_mean_length,\n",
    "        'firing_rate_bursts': firing_rate_bursts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimulationStatistician(object):\n",
    "    \n",
    "    \"\"\" A class to simplify the job of calculating spiking statistics from a\n",
    "    simulation with a given set of parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tmax, dt, **kwargs):\n",
    "        \"\"\" Set the parameters of the simulation.\n",
    "        \n",
    "        Any extra arguments apart from `n_reps` get passed directly to\n",
    "        `SpikingLearningSimulation`.\n",
    "        \"\"\"\n",
    "        # the simulator class needs a target, but it's irrelevant for our purposes\n",
    "        self.tmax = tmax\n",
    "        self.dt = dt\n",
    "        self.target = np.zeros((1, int_r(self.tmax/self.dt)))\n",
    "        self.n_reps = kwargs.pop('n_reps', 1)\n",
    "        \n",
    "        def tracker_generator(simulator, i, n):\n",
    "            \"\"\" Generate some trackers. \"\"\"\n",
    "            res = {}\n",
    "            res['student_spike'] = simulation.EventMonitor(simulator.student)\n",
    "\n",
    "            return res\n",
    "        \n",
    "        default_args = {\n",
    "            'n_student_per_output': 10,\n",
    "            'plasticity_learning_rate': 0,\n",
    "            'tutor_rule_gain': 0,\n",
    "            'tracker_generator': tracker_generator\n",
    "        }        \n",
    "        default_args.update(kwargs)\n",
    "        \n",
    "        self.default_args = default_args\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        \"\"\" Run the simulation and return the statistics.\n",
    "        \n",
    "        If the keyword argument `combine_reps` is `False` (the default), the\n",
    "        function returns a list of dictionaries, one for each repetition of the\n",
    "        simulation. Otherwise, all the spikes get collected in one vector whose\n",
    "        statistics are returned.\n",
    "        \n",
    "        Any other keyword arguments are passed to `SpikingLearningSimulation`.\n",
    "        \"\"\"\n",
    "        combine_reps = kwargs.pop('combine_reps', False)\n",
    "        \n",
    "        self.args = dict(self.default_args)\n",
    "        self.args.update(kwargs)\n",
    "        \n",
    "        self.last_simulator = SpikingLearningSimulation(self.target, self.tmax, self.dt,\n",
    "                                                        **self.args)\n",
    "        self.last_res = self.last_simulator.run(self.n_reps)\n",
    "        \n",
    "        if not combine_reps:\n",
    "            stats = []\n",
    "            for crt_res in self.last_res:\n",
    "                crt_isi = collect_isi([crt_res['student_spike']], tmax=self.tmax)\n",
    "                # division to convert from ms to s!\n",
    "                stats.append(calculate_statistics(crt_isi/1000.0))\n",
    "                \n",
    "            return stats\n",
    "        else:\n",
    "            # division to convert from ms to s!\n",
    "            return calculate_statistics(collect_isi([_['student_spike'] for _ in self.last_res],\n",
    "                                                    tmax=self.tmax)/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_stats(stats_list):\n",
    "    \"\"\" Take the average over the values of a list of dictionaries.\n",
    "    \n",
    "    Values that cannot be averaged are not included in the final result.\n",
    "    \"\"\"\n",
    "    keys = stats_list[0].keys()\n",
    "    res = {}\n",
    "    n = float(len(stats_list))\n",
    "    for crt_key in keys:\n",
    "        crt_values = [_[crt_key] for _ in stats_list]\n",
    "        try:\n",
    "            crt_avg = sum(crt_values)/n\n",
    "            res[crt_key] = crt_avg\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_summary_stats_violins(epochs, all_stats, all_ages, simstats, title_map, order,\n",
    "                               color=[0.831, 0.333, 0.000],\n",
    "                               plot_min_age=43, plot_max_age=160, simpos='left'):\n",
    "    \"\"\" Draw a violin plot comparing different bird ages and simulation results statistics.\n",
    "    \"\"\"\n",
    "    n_plots = len(order)\n",
    "    nx = int(math.ceil(math.sqrt(n_plots)))\n",
    "    ny = int(math.ceil(float(n_plots)/nx))\n",
    "    \n",
    "    epoch_stats = []\n",
    "    for crt_epoch in epochs:\n",
    "        epoch_stats.append([crt_stats for (crt_stats, crt_age) in zip(all_stats, all_ages)\n",
    "                            if crt_age >= crt_epoch[0] and crt_age < crt_epoch[1]])\n",
    "    \n",
    "    for (i, crtplot) in enumerate(order):\n",
    "        data = []\n",
    "        colors = []\n",
    "        names = []\n",
    "        plt.subplot(ny, nx, 1+i)\n",
    "        for (crt_epoch, crt_stats) in zip(epochs, epoch_stats):\n",
    "            values = np.asarray([x[crtplot] for x in crt_stats])\n",
    "            crt_dph = np.mean(crt_epoch)\n",
    "\n",
    "            data.append(values)\n",
    "            colors.append(color)\n",
    "            names.append('{}-{}'.format(*crt_epoch))\n",
    "        \n",
    "        # now append the simulated values\n",
    "        simvalues = np.asarray([x[crtplot] for x in simstats])\n",
    "        simcolor = (0.2, 0.5, 1.0)\n",
    "        simtext = 'sim'\n",
    "        if simpos == 'right':\n",
    "            data.append(simvalues)\n",
    "            colors.append(simcolor)\n",
    "            names.append(simtext)\n",
    "        elif simpos == 'left':\n",
    "            data.insert(0, simvalues)\n",
    "            colors.insert(0, simcolor)\n",
    "            names.insert(0, simtext)\n",
    "        else:\n",
    "            raise Exception('Unknown simpos.')\n",
    "        \n",
    "        # and draw!\n",
    "        sns.violinplot(data=data, palette=colors, scale='width')\n",
    "        plt.xticks(range(len(names)), names, rotation=45)\n",
    "        plt.ylim(0, plt.ylim()[1])\n",
    "\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.ylabel(title_map[crtplot])\n",
    "        \n",
    "#        plt.gca().title.set_fontsize(10)\n",
    "        plt.gca().yaxis.label.set_fontsize(8)\n",
    "        for _ in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "            _.set_fontsize(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_summary_stats_violins_double(epochs, all_stats, all_ages, simstats1, simstats2, \n",
    "                               title_map, order,\n",
    "                               color=[0.831, 0.333, 0.000],\n",
    "                               plot_min_age=43, plot_max_age=160, simtext=['sim1', 'sim2']):\n",
    "    \"\"\" Draw a violin plot comparing different bird ages and simulation results statistics.\n",
    "    \"\"\"\n",
    "    n_plots = len(order)\n",
    "    nx = int(math.ceil(math.sqrt(n_plots)))\n",
    "    ny = int(math.ceil(float(n_plots)/nx))\n",
    "    \n",
    "    epoch_stats = []\n",
    "    for crt_epoch in epochs:\n",
    "        epoch_stats.append([crt_stats for (crt_stats, crt_age) in zip(all_stats, all_ages)\n",
    "                            if crt_age >= crt_epoch[0] and crt_age < crt_epoch[1]])\n",
    "    \n",
    "    for (i, crtplot) in enumerate(order):\n",
    "        data = []\n",
    "        colors = []\n",
    "        names = []\n",
    "        plt.subplot(ny, nx, 1+i)\n",
    "        for (crt_epoch, crt_stats) in zip(epochs, epoch_stats):\n",
    "            values = np.asarray([x[crtplot] for x in crt_stats])\n",
    "            crt_dph = np.mean(crt_epoch)\n",
    "\n",
    "            data.append(values)\n",
    "            colors.append(color)\n",
    "            names.append('{}-{}'.format(*crt_epoch))\n",
    "        \n",
    "        # now append the simulated values\n",
    "        simvalues1 = np.asarray([x[crtplot] for x in simstats1])\n",
    "        simvalues2 = np.asarray([x[crtplot] for x in simstats2])\n",
    "        simcolor = (0.2, 0.5, 1.0)\n",
    "\n",
    "        data.append(simvalues2)\n",
    "        colors.append(simcolor)\n",
    "        names.append(simtext[1])\n",
    "\n",
    "        data.insert(0, simvalues1)\n",
    "        colors.insert(0, simcolor)\n",
    "        names.insert(0, simtext[0])\n",
    "        \n",
    "        # and draw!\n",
    "        sns.violinplot(data=data, palette=colors, scale='width')\n",
    "        plt.xticks(range(len(names)), names, rotation=45)\n",
    "        plt.ylim(0, plt.ylim()[1])\n",
    "\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.ylabel(title_map[crtplot])\n",
    "        \n",
    "        plt.gca().yaxis.label.set_fontsize(8)\n",
    "        for _ in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "            _.set_fontsize(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load experimental spiking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spike_stats_raw = scipy.io.loadmat(\"data/allCellsNew.mat\",\n",
    "                                   squeeze_me=True, chars_as_strings=True,\n",
    "                                   struct_as_record=False)\n",
    "all_data = spike_stats_raw['allCellsNew']\n",
    "isi_data = np.asarray([_.spikeI for _ in all_data])\n",
    "ages = np.asarray([x.dph for x in all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data below 200 dph, because the 200 dph birds are all directed singing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_mask = (ages < 200)\n",
    "selected_isi_data = isi_data[selected_mask]\n",
    "selected_ages = ages[selected_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate statistics of experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_stats = np.asarray([calculate_statistics(crt_isi) for crt_isi in isi_data])\n",
    "selected_stats = all_stats[selected_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_title_map = {\n",
    "    'burst_mean_length': 'Mean duration of bursts (s)',\n",
    "    'burst_rate': 'Rate at which bursts occur (Hz)',\n",
    "    'cv': 'Coefficient of variation',\n",
    "    'fano_factor': 'Fano factor (s)',\n",
    "    'firing_rate': 'Average firing rate (Hz)',\n",
    "    'firing_rate_bursts': 'Average firing rate during bursts (Hz)',\n",
    "    'isi_mean': 'Mean inter-spike interval (s)',\n",
    "    'isi_std': 'Standard deviation of inter-spike intervals (s)',\n",
    "    'isi_skew': 'Skewness of inter-spike interval distribution'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make linear predictor of age based on stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor_names = ['constant'] + stats_title_map.keys()\n",
    "selected_summary_stats = np.column_stack(\n",
    "    [(x[name] if name != 'constant' else 1) for x in selected_stats]\n",
    "    for name in predictor_names)\n",
    "lincoeffs, linresiduals, _, _ = np.linalg.lstsq(selected_summary_stats, np.asarray(selected_ages, dtype=float))\n",
    "lincoeffs_mapped = {name: lincoeffs[i] for (i, name) in enumerate(predictor_names)}\n",
    "guessed_selected_ages = np.dot(selected_summary_stats, lincoeffs)\n",
    "print('Size of residuals is {:.2f} dph.'.format(np.sqrt(linresiduals[0]/(len(selected_ages)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(selected_ages, guessed_selected_ages, alpha=0.6)\n",
    "plt.scatter([selected_ages[68]], [guessed_selected_ages[68]], c='r')   # juvenile\n",
    "plt.scatter([selected_ages[122]], [guessed_selected_ages[122]], c='g') # adult\n",
    "plt.xlabel(\"Real age (dph)\")\n",
    "plt.ylabel(\"Age inferred from linear model (dph)\")\n",
    "print \"Correlation coefficient: {:.2f}.\".format(np.corrcoef(selected_ages, guessed_selected_ages)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find summary statistics that are very similar to one-another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(np.corrcoef(selected_summary_stats.T), square=True, vmin=-1.0, vmax=1.0)\n",
    "predictor_names_disp = [s.replace('_', ' ') for s in predictor_names]\n",
    "plt.xticks(0.5 + np.arange(len(predictor_names_disp)), predictor_names_disp, rotation='vertical')\n",
    "# XXX seaborn seems to flip the labels but not the coordinates!\n",
    "plt.yticks(len(predictor_names_disp) - 0.5 - np.arange(len(predictor_names_disp)),\n",
    "           predictor_names_disp, rotation='horizontal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for simulation parameters that best model measured spiking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pack_params(d, selection):\n",
    "    \"\"\" Convert a subset of the values in the dictionary `d` (selected\n",
    "    by the list `selection`) into a vector.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for crt_name in selection:\n",
    "        # handle multi-component values\n",
    "        i = crt_name.find('::')\n",
    "        if i == -1:\n",
    "            res.append(d[crt_name])\n",
    "        else:\n",
    "            crt_value = d[crt_name]\n",
    "            if not hasattr(crt_value, '__len__') or len(crt_value) != int(crt_name[i+2:]):\n",
    "                raise Exception('Mismatch between name and length of value.')\n",
    "            \n",
    "            res.extend(crt_value)\n",
    "    \n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_params(x, selection):\n",
    "    \"\"\" Convert the values from `pack_params` back to a dictionary. \"\"\"\n",
    "    res = {}\n",
    "    k = 0\n",
    "    for crt_name in selection:\n",
    "        i = crt_name.find('::')\n",
    "        if i == -1:\n",
    "            res[crt_name] = x[k]\n",
    "            k += 1\n",
    "        else:\n",
    "            crt_n = int(crt_name[i+2:])\n",
    "            res[crt_name] = tuple(x[k:k+crt_n])\n",
    "            k += crt_n\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize_keys(d):\n",
    "    \"\"\" 'Sanitize' the keys in the dictionary by removing any trailing '::<number>'\n",
    "    parts.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, value in d.items():\n",
    "        i = key.find('::')\n",
    "        if i < 0:\n",
    "            res[key] = value\n",
    "        else:\n",
    "            res[key[:i]] = value\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bounds_trafo(bounds_dict, selection):\n",
    "    \"\"\" Generate 'genotype' to 'phenotype' and reverse transformations\n",
    "    for use with CMA-ES.\n",
    "    \"\"\"\n",
    "    bounds = pack_params(bounds_dict, selection)\n",
    "    def bounds_trafo(x):\n",
    "        return bounds[:, 0] + 0.5*(bounds[:, 1] - bounds[:, 0])*(1.0 - np.cos(np.pi*x/10.0))\n",
    "\n",
    "    def bounds_rev_trafo(y):\n",
    "        return 10.0/np.pi*np.arccos(1.0 - 2.0*(y - bounds[:, 0])/(bounds[:, 1] - bounds[:, 0]))\n",
    "    \n",
    "    return (bounds_trafo, bounds_rev_trafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters to optimize and objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose statistics to optimize\n",
    "optim_stats = ['firing_rate', 'cv', 'isi_skew', 'burst_rate', 'burst_mean_length', 'firing_rate_bursts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stats_diff(stats1, stats2, optim_stats):\n",
    "    \"\"\" Calculate the difference between two stats. \"\"\"\n",
    "    ratios = [stats1[key] / stats2[key] for key in optim_stats]\n",
    "    return np.linalg.norm(np.asarray(ratios) - 1.0)/np.sqrt(len(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ObjectiveFunction(object):\n",
    "    \n",
    "    \"\"\" An objective function that calculates spiking statistics, for use\n",
    "    with CMA-ES.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\" Initialize the objective function.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "          target_stats: dictionary\n",
    "              Target values for the statistics.\n",
    "          optim_stats: list\n",
    "              Select the statistics that are optimized.\n",
    "          selection: list\n",
    "              Parameters that are being optimized.\n",
    "          pack_fct:\n",
    "          unpack_fct:\n",
    "              Functions that pack and unpack the parameters between vector\n",
    "              form and dictionary form. Their signatures are\n",
    "                  pack_fct(dict, selection)\n",
    "                  unpack_fct(x, selection)\n",
    "        \n",
    "        All other arguments are passed directly to `SimulationStatistician`.\n",
    "        \"\"\"\n",
    "        self.target_stats = kwargs.pop('target_stats')\n",
    "        self.optim_stats = kwargs.pop('optim_stats')\n",
    "        self.selection = kwargs.pop('selection')\n",
    "        self.defaults = kwargs.pop('defaults')\n",
    "        \n",
    "        self.pack_fct = kwargs.pop('pack_fct')\n",
    "        self.unpack_fct = kwargs.pop('unpack_fct')\n",
    "        \n",
    "        self.statistician = SimulationStatistician(*args, **kwargs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\" Calculate how different the statistics of the simulation given the\n",
    "        parameters `x` are from the target statistics.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "          x\n",
    "              Numeric array describing the parameters for the simulation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "          A single number representing a measure of how far the current simulation is\n",
    "          from the target, in terms of the summary statistics identified by `self.optim_stats`.\n",
    "          \n",
    "          Given the current and target values of the statistics, `crt` and `tgt`, the\n",
    "          output is\n",
    "            `np.linalg.norm(crt/tgt - 1.0)/len(crt)`\n",
    "        \"\"\"\n",
    "        args = dict(self.defaults)\n",
    "        args.update(self.unpack_fct(x, self.selection))\n",
    "        \n",
    "        args = sanitize_keys(args)\n",
    "        \n",
    "        stats = self.statistician(**args)\n",
    "        if len(stats) > 1:\n",
    "            avg_stats = average_stats(stats)\n",
    "        else:\n",
    "            avg_stats = stats[0]\n",
    "        \n",
    "        self.avg_stats = avg_stats\n",
    "        \n",
    "        return stats_diff(self.avg_stats, self.target_stats, self.optim_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_args(args, i):\n",
    "    \"\"\" Keep the arguments that are common (i.e., have no '##' in their names)\n",
    "    or belong to simulation `i` (i.e., have '##' + str(i) in their names).\n",
    "    \"\"\"\n",
    "    crt_args = {}\n",
    "    for key, value in args.items():\n",
    "        # get rid of any length indicators\n",
    "        pound_j = key.find('::')\n",
    "        if pound_j >= 0:\n",
    "            key = key[:pound_j]\n",
    "        pound_i = key.find('##')\n",
    "        if pound_i < 0:\n",
    "            # a common argument\n",
    "            crt_args[key] = value\n",
    "        elif int(key[pound_i+2:]) == i:\n",
    "            # keep only the arguments meant for this simulation\n",
    "            crt_args[key[:pound_i]] = value\n",
    "    \n",
    "    return crt_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dicts(d1, d2):\n",
    "    \"\"\" Merge the two dictionaries, keeping values from the second\n",
    "    one whenever there is overlap of keys.\n",
    "    \"\"\"\n",
    "    d = dict(d1)\n",
    "    d.update(d2)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultipleObjectiveFunction(object):\n",
    "\n",
    "    \"\"\" An objective function that optimizes the results of several\n",
    "    simulations instead of one.\n",
    "    \n",
    "    The simulations share some parameters, while others are separate.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\" Initialize the objective function.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "          target_stats: list of dictionaries\n",
    "              Target values for the statistics.\n",
    "          optim_stats: list\n",
    "              Select the statistics that are optimized.\n",
    "          selection: list\n",
    "              Parameters that are being optimized. Parameters that have names\n",
    "              of the form 'param##0' or 'param##2::3' are specific to a given\n",
    "              simulation (index 0 or 2, respectively, for these examples).\n",
    "              Other parameters are common for all simulations. Note that the\n",
    "              indication for vector parameters ('::3' here) comes after the\n",
    "              simulation index.\n",
    "          defaults: dict\n",
    "              Default parameters that are used if they are not replaced by any\n",
    "              of the values from `selection`.\n",
    "          pack_fct:\n",
    "          unpack_fct:\n",
    "              Functions that pack and unpack parameters between vector\n",
    "              form and dictionary form. Their signatures are\n",
    "                  pack_fct(dict, selection)\n",
    "                  unpack_fct(x, selection)\n",
    "        \n",
    "        All other arguments are passed directly to `SimulationStatistician`.\n",
    "        \"\"\"\n",
    "        self.target_stats = kwargs.pop('target_stats')\n",
    "        self.optim_stats = kwargs.pop('optim_stats')\n",
    "        self.selection = kwargs.pop('selection')\n",
    "        self.defaults = kwargs.pop('defaults')\n",
    "        \n",
    "        self.pack_fct = kwargs.pop('pack_fct')\n",
    "        self.unpack_fct = kwargs.pop('unpack_fct')\n",
    "        \n",
    "        self.n = len(self.target_stats)\n",
    "        self.statisticians = [SimulationStatistician(*args, **kwargs) for _ in xrange(self.n)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\" Calculate how different the statistics of the simulations given the\n",
    "        parameters `x` are from the target statistics.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "          x\n",
    "              Numeric array describing the parameters for the simulations.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "          A single number representing a measure of how far the current simulations are\n",
    "          from their targets, in terms of the summary statistics identified by\n",
    "          `self.optim_stats`.\n",
    "          \n",
    "          Given the current and target values of the statistics, `crt[i]` and `tgt[i]`, the\n",
    "          output is\n",
    "            `np.mean(np.linalg.norm(crt/tgt - 1.0)/len(crt))`\n",
    "        \"\"\"\n",
    "        args = dict(self.defaults)\n",
    "        args.update(self.unpack_fct(x, self.selection))\n",
    "        args = sanitize_keys(args)\n",
    "        \n",
    "        avg_stats = []\n",
    "        \n",
    "        for i, crt_statistician in enumerate(self.statisticians):\n",
    "            crt_args = split_args(args, i)\n",
    "            \n",
    "            crt_stats = crt_statistician(**crt_args)\n",
    "            if len(crt_stats) > 1:\n",
    "                crt_stats = average_stats(crt_stats)\n",
    "            else:\n",
    "                crt_stats = crt_stats[0]\n",
    "            \n",
    "            avg_stats.append(crt_stats)\n",
    "        \n",
    "        self.avg_stats = avg_stats\n",
    "        \n",
    "        diffs = [stats_diff(crt, tgt, self.optim_stats) for (crt, tgt) in\n",
    "                 zip(self.avg_stats, self.target_stats)]\n",
    "        \n",
    "        return np.mean(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use CMA-ES to jointly optimize juvenile and adult simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose recordings to use for juvenile and adult bird, respectively\n",
    "idx_juvenile = 68\n",
    "idx_adult = 122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose ranges for common parameters\n",
    "optim_range = {    \n",
    "    'conductor_rate_during_burst': (400, 800),\n",
    "    'student_vR': (-75.0, -65.0),\n",
    "    'student_v_th': (-55.0, -45.0),\n",
    "    'student_R': (100.0, 400.0),\n",
    "    'student_tau_m': (10.0, 25.0),\n",
    "    'student_tau_ampa': (3.0, 15.0),\n",
    "    'student_tau_nmda': (80.0, 120.0),\n",
    "    'student_g_inh': (0.1, 2.0),\n",
    "#    'student_i_external': (-0.5, -0.05),\n",
    "    'student_tau_ref': (1.0, 2.0),\n",
    "    'cs_weights_params##0::2': ((-3.62, -3.52), (0.50, 0.58)),\n",
    "    'cs_weights_params##1::2': ((-2.87, -2.71), (0.71, 0.81)),\n",
    "    'cs_weights_fraction##0': (0.06, 0.5),\n",
    "    'cs_weights_fraction##1': (0.03, 0.5),\n",
    "    'ts_weights': (0.10, 0.20)\n",
    "}\n",
    "optim_params = ['conductor_rate_during_burst', 'student_v_th', 'student_R', 'student_vR',\n",
    "                'student_tau_m', 'student_tau_ampa',\n",
    "                'student_tau_nmda', 'student_tau_ref', #'student_i_external',\n",
    "                'student_g_inh',\n",
    "                'cs_weights_params##0::2', 'cs_weights_params##1::2',\n",
    "                'cs_weights_fraction##0', 'cs_weights_fraction##1', 'ts_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose a starting point (guess values)\n",
    "guess_params = {\n",
    "    'conductor_rate_during_burst': 718.0,\n",
    "    'cs_weights_fraction##0': 0.4,\n",
    "    'cs_weights_fraction##1': 0.17,\n",
    "    'cs_weights_params##0::2': (-3.54, 0.54),\n",
    "    'cs_weights_params##1::2': (-2.72, 0.76),\n",
    "    'student_R': 400.0,\n",
    "    'student_g_inh': 1.48,\n",
    "    'student_tau_ampa': 4.8,\n",
    "    'student_tau_m': 24.5,\n",
    "    'student_tau_nmda': 94.4,\n",
    "    'student_tau_ref': 1.9,\n",
    "    'student_vR': -73.7,\n",
    "    'student_v_th': -53.1,\n",
    "    'ts_weights': 0.12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# length and timestep of simulation\n",
    "tmax = 600.0\n",
    "dt = 0.2\n",
    "\n",
    "objective = MultipleObjectiveFunction(tmax, dt,\n",
    "                              target_stats=[selected_stats[idx_juvenile], selected_stats[idx_adult]],\n",
    "                              optim_stats=optim_stats, selection=optim_params,\n",
    "                              defaults=guess_params,\n",
    "                              pack_fct=pack_params, unpack_fct=unpack_params,\n",
    "                              n_conductor=300, n_student_per_output=100,\n",
    "                              relaxation=400.0, relaxation_conductor=25.0,\n",
    "                              plasticity_constrain_positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bounds_trafos = get_bounds_trafo(optim_range, optim_params)\n",
    "# run the optimization -- this can take a while\n",
    "cma_res = cma.fmin(\n",
    "        objective, pack_params(guess_params, optim_params), sigma0=3.0,\n",
    "        options={'tolfun': 1e-3, 'tolfunhist': 1e-4, 'tolx': 1e-4,\n",
    "             'transformation': bounds_trafos,\n",
    "             'maxfevals': 1000, 'verb_disp': 1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = unpack_params(cma_res[0], optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save parameters to file\n",
    "best_params_full = merge_dicts(objective.statisticians[0].default_args,\n",
    "           sanitize_keys(merge_dicts(objective.defaults, best_params)))\n",
    "\n",
    "# get rid of tracker/snapshot generators\n",
    "best_params_full.pop('tracker_generator', None)\n",
    "best_params_full.pop('snapshot_generator', None)\n",
    "\n",
    "# include some extra data\n",
    "best_params_full['tmax'] = tmax\n",
    "best_params_full['dt'] = dt\n",
    "\n",
    "# do the actual saving\n",
    "imax = 1000\n",
    "for i in xrange(imax):\n",
    "    # save to the first available slot, name ending in _0, _1, _2, ...\n",
    "    file_name = 'best_params_joint_{}.pkl'.format(i)\n",
    "    if os.path.exists(file_name):\n",
    "        continue\n",
    "    \n",
    "    with open(file_name, 'wb') as out:\n",
    "        pickle.dump(best_params_full, out, 2)\n",
    "    \n",
    "    break\n",
    "    \n",
    "# copy the resulting file to default_params.pkl to be used by the figure-making code\n",
    "# below and by the simulation code in spiking_simulations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cma_res[-1].load()\n",
    "plt.plot(np.min(cma_res[-1].f, axis=1))\n",
    "plt.xlabel('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the spiking patterns for joint optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args_juvenile = merge_dicts(objective.statisticians[0].default_args,\n",
    "                           split_args(merge_dicts(guess_params, best_params), 0))\n",
    "args_adult = merge_dicts(objective.statisticians[1].default_args,\n",
    "                        split_args(merge_dicts(guess_params, best_params), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_juvenile = SpikingLearningSimulation(objective.statisticians[0].target, tmax, dt, **args_juvenile)\n",
    "res_juvenile = sim_juvenile.run(10)\n",
    "stats_juvenile = calculate_statistics(collect_isi([_['student_spike'] for _ in res_juvenile],\n",
    "        tmax=tmax)/1000.0)\n",
    "\n",
    "sim_adult = SpikingLearningSimulation(objective.statisticians[1].target, tmax, dt, **args_adult)\n",
    "res_adult = sim_adult.run(10)\n",
    "stats_adult = calculate_statistics(collect_isi([_['student_spike'] for _ in res_adult],\n",
    "        tmax=tmax)/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_repetition_pattern([_['student_spike'] for _ in res_juvenile], idx=range(10), ms=2)\n",
    "plt.xlim(0, tmax);\n",
    "plt.title('Juvenile bird');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_repetition_pattern([_['student_spike'] for _ in res_adult], idx=range(10), ms=2)\n",
    "plt.xlim(0, tmax);\n",
    "plt.title('Adult bird');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the default parameters\n",
    "with open('default_params.pkl', 'rb') as inp:\n",
    "    default_params = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tracker_generator(simulator, i, n):\n",
    "    \"\"\" Generate some trackers. \"\"\"\n",
    "    res = {}\n",
    "    res['student_spike'] = simulation.EventMonitor(simulator.student)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_params = dict(default_params)\n",
    "actual_params['tracker_generator'] = tracker_generator\n",
    "actual_params.pop('target')\n",
    "#sim = SpikingLearningSimulation(**actual_params)\n",
    "#res = sim.run(10)\n",
    "t0 = time.time()\n",
    "sim = SimulationStatistician(n_reps=50, **actual_params)\n",
    "res = sim()\n",
    "t1 = time.time()\n",
    "print(\"Simuation took {:.2f} seconds.\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [(i, i+25) for i in xrange(40, 160, 25)]\n",
    "short_title_map = {\n",
    "    'burst_mean_length': 'Average burst length (s)',\n",
    "    'burst_rate': 'Burst frequency (Hz)',\n",
    "    'cv': 'CV of ISI',\n",
    "    'fano_factor': 'Fano factor (s)', # XXX what's the right normalization to get this to be dimensionless?\n",
    "    'firing_rate': 'Average firing rate (Hz)',\n",
    "    'firing_rate_bursts': 'Firing rate during bursts (Hz)',\n",
    "    'isi_mean': 'Average ISI (s)',\n",
    "    'isi_std': 'Standard deviation of ISI (s)',\n",
    "    'isi_skew': 'Skewness of ISI'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6, 3.8])\n",
    "draw_summary_stats_violins(epochs, selected_stats, selected_ages,\n",
    "                           simstats=res, title_map=short_title_map,\n",
    "                           order=['firing_rate', 'cv', 'isi_skew',\n",
    "                                  'burst_rate', 'burst_mean_length',\n",
    "                                  'firing_rate_bursts'])\n",
    "plt.tight_layout()\n",
    "\n",
    "safe_save_fig('figs/spiking_matching_violins', png=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_params_adult = actual_params\n",
    "actual_params_adult['cs_weights_fraction'] = 0.15157340812668241\n",
    "actual_params_adult['cs_weights_params'] = (-2.7101150158852856, 0.80989719997502518)\n",
    "t0 = time.time()\n",
    "sim_adult = SimulationStatistician(n_reps=50, **actual_params_adult)\n",
    "res_adult = sim_adult()\n",
    "t1 = time.time()\n",
    "print(\"Simuation took {:.2f} seconds.\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6, 3.8])\n",
    "draw_summary_stats_violins_double(epochs, selected_stats, selected_ages,\n",
    "                           simstats1=res, simstats2=res_adult,\n",
    "                           title_map=short_title_map,\n",
    "                           order=['firing_rate', 'cv', 'isi_skew',\n",
    "                                  'burst_rate', 'burst_mean_length',\n",
    "                                  'firing_rate_bursts'],\n",
    "                           simtext=['sim juvenile', 'sim adult'])\n",
    "plt.tight_layout()\n",
    "\n",
    "safe_save_fig('figs/spiking_matching_violins_double', png=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
